{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC_GRID = '//div[@class=\"grid grid-cols-4 sm:grid-cols-5 md:grid-cols-6 lg:grid-cols-7 xl:grid-cols-8 h-100 p-3 text-slate-950\"]'\n",
    "\n",
    "class LCStatScraper:\n",
    "    def __init__(self, url):\n",
    "        self.driver = None\n",
    "        self.url = url\n",
    "\n",
    "    def create_driver(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        self.driver.get(self.url)\n",
    "        self.driver.maximize_window()\n",
    "    \n",
    "    def mine_lcs(self):\n",
    "        lc_grid = self.wait.until(EC.presence_of_element_located((By.XPATH, LC_GRID)))\n",
    "        lc_list = lc_grid.find_elements(By.TAG_NAME, 'a')\n",
    "        return_dict = {}\n",
    "        for i in range(len(lc_list)):\n",
    "            lc_dict = {}\n",
    "\n",
    "            # refresh references\n",
    "            lc_grid = self.wait.until(EC.presence_of_element_located((By.XPATH, LC_GRID)))\n",
    "            lc_list = lc_grid.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "            # get name and ID\n",
    "            lc_link = lc_list[i]\n",
    "            \n",
    "            name = lc_link.find_element(By.TAG_NAME, 'div').get_attribute('innerText')\n",
    "            id = lc_link.get_attribute('href').split('/')[-1]\n",
    "\n",
    "            image_link = lc_link.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "\n",
    "            lc_dict['Name'] = name\n",
    "            lc_dict['ImageLink'] = image_link\n",
    "            return_dict[id] = lc_dict\n",
    "        self.driver.close()\n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAKUSHIN_URL = 'https://hsr2.hakush.in/lightcone'\n",
    "\n",
    "scraper = LCStatScraper(HAKUSHIN_URL)\n",
    "scraper.create_driver()\n",
    "lc_dict = scraper.mine_lcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datamine/EquipmentPromotionConfig.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "def organize_lc_data(data, id):\n",
    "    ascensions = [\n",
    "        data[id]['0'],\n",
    "        data[id]['1'],\n",
    "        data[id]['2'],\n",
    "        data[id]['3'],\n",
    "        data[id]['4'],\n",
    "        data[id]['5'],\n",
    "        data[id]['6']\n",
    "    ]\n",
    "    \n",
    "    level_data = {}\n",
    "\n",
    "    # handle this in sections\n",
    "    for i in range(len(ascensions)):\n",
    "        current_ascension = ascensions[i]\n",
    "        min_level, max_level = 1, 0\n",
    "        if i == 0:\n",
    "            max_level = ascensions[i]['MaxLevel']\n",
    "        else:\n",
    "            min_level = ascensions[i-1]['MaxLevel']\n",
    "            max_level = ascensions[i]['MaxLevel']\n",
    "\n",
    "        base_atk = current_ascension['BaseAttack']['Value']\n",
    "        base_def = current_ascension['BaseDefence']['Value']\n",
    "        base_hp = current_ascension['BaseHP']['Value']\n",
    "\n",
    "        atk_add = current_ascension['BaseAttackAdd']['Value']\n",
    "        def_add = current_ascension['BaseDefenceAdd']['Value']\n",
    "        hp_add = current_ascension['BaseHPAdd']['Value']\n",
    "        \n",
    "        # now that we know min and max level, fill in the values\n",
    "        for j in range(min_level, max_level+1):\n",
    "            stat_object = {}\n",
    "            current_atk = round((base_atk + atk_add*(j-1)), 3)\n",
    "            current_def = round((base_def + def_add*(j-1)), 3)\n",
    "            current_hp = round((base_hp + hp_add*(j-1)), 3)\n",
    "            level_tag = str(j)\n",
    "            if (j == min_level) & (j != 1):\n",
    "                # we're doing the x+\n",
    "                level_tag = str(min_level) + '+'\n",
    "            stat_object['ATK'] = current_atk\n",
    "            stat_object['DEF'] = current_def\n",
    "            stat_object['HP'] = current_hp\n",
    "            level_data[level_tag] = stat_object\n",
    "    return level_data\n",
    "\n",
    "for i in lc_dict.keys():\n",
    "    lc_dict[i]['BaseStats'] = organize_lc_data(json_data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../data/hsr_lc_stats.json', 'w') as f:\n",
    "    json.dump(lc_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
