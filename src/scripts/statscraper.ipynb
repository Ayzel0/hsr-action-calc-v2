{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNRELEASED_SELECT = '//select[@class=\"font-medium rounded-md text-blazer-950 text-right pb-0.5\"]'\n",
    "CLOSE_SETTINGS_MENU_ICON = '//div[@class=\"absolute right-3 cursor-pointer p-4\"]'\n",
    "CHAR_SELECT_ICON = '//a[@href=\"/en/archive/avatar\"]'\n",
    "CHAR_GRID = '//div[@class=\"flex flex-row flex-wrap justify-center gap-6 mt-2\"]'\n",
    "CHAR_NAME = './/div[@class=\"text-2xl font-bold text-white xl:text-3xl\"]'\n",
    "\n",
    "class StatMiner:\n",
    "    def __init__(self, target_url):\n",
    "        self.target_url = target_url\n",
    "        self.driver = None\n",
    "    \n",
    "    def create_driver(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(self.target_url)\n",
    "        self.driver.maximize_window()\n",
    "\n",
    "    def close_menu(self):\n",
    "        # close the settings menu\n",
    "        settings_title = self.driver.find_element(By.XPATH, '//div[@name=\"title\"]')\n",
    "        x_button = settings_title.find_element(By.XPATH, CLOSE_SETTINGS_MENU_ICON)\n",
    "        x_button.click()\n",
    "\n",
    "    def get_chars(self):\n",
    "        # find the div which contains all char links\n",
    "        char_grid = WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, CHAR_GRID))\n",
    "        )\n",
    "        all_characters = char_grid.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "        # loop\n",
    "        df_list = []\n",
    "        name_list = []\n",
    "        for i in range(len(all_characters)):\n",
    "            char_grid = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, CHAR_GRID))\n",
    "            )\n",
    "            all_characters = char_grid.find_elements(By.TAG_NAME, 'a')\n",
    "            all_characters[i].click()\n",
    "\n",
    "            # find character name\n",
    "            char_name_div = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, 'Avatar Name'))\n",
    "            )\n",
    "            char_name = char_name_div.find_element(By.XPATH, CHAR_NAME).get_attribute('innerText')\n",
    "            name_list.append(char_name)\n",
    "            print(char_name)\n",
    "            \n",
    "            # find the slider button to convert to table\n",
    "            slider_button = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//button[text()=\"Slider\"]'))\n",
    "            )\n",
    "            slider_button.click()\n",
    "\n",
    "            # get a dataframe from the table\n",
    "            stat_table = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.NAME, 'STAT TABLE'))\n",
    "            )\n",
    "            stat_table_html = stat_table.get_attribute('outerHTML')\n",
    "            char_df = pd.read_html(stat_table_html)[0]\n",
    "            df_list.append(char_df)\n",
    "\n",
    "            self.driver.back()\n",
    "        return df_list, name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misha\n",
      "Sparkle\n",
      "Black Swan\n",
      "Dr. Ratio\n",
      "Xueyi\n",
      "Ruan Mei\n",
      "Hanya\n",
      "Argenti\n",
      "Huohuo\n",
      "Topaz & Numby\n",
      "Guinaifen\n",
      "Jingliu\n",
      "Lynx\n",
      "Fu Xuan\n",
      "Dan Heng â€¢ Imbibitor Lunae\n",
      "Kafka\n",
      "Luka\n",
      "Blade\n",
      "Luocha\n",
      "Yukong\n",
      "Silver Wolf\n",
      "Jing Yuan\n",
      "March 7th\n",
      "Dan Heng\n",
      "Himeko\n",
      "Welt\n",
      "Arlan\n",
      "Asta\n",
      "Herta\n",
      "Bronya\n",
      "Seele\n",
      "Serval\n",
      "Gepard\n",
      "Natasha\n",
      "Pela\n",
      "Clara\n",
      "Sampo\n",
      "Hook\n",
      "Qingque\n",
      "Tingyun\n",
      "Sushang\n",
      "Yanqing\n",
      "Bailu\n",
      "Trailblazer\n",
      "Trailblazer\n",
      "Trailblazer\n",
      "Trailblazer\n"
     ]
    }
   ],
   "source": [
    "YATTA_URL = 'https://hsr.yatta.top/en/archive/avatar'\n",
    "scraper = StatMiner(YATTA_URL)\n",
    "scraper.create_driver()\n",
    "scraper.close_menu()\n",
    "df_list, name_list = scraper.get_chars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/hsr_char_stats.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dfs:\n\u001b[0;32m     26\u001b[0m     character_stats\u001b[38;5;241m.\u001b[39mappend(convert_to_json(df))\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/hsr_char_stats.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     29\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(character_stats, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andre\\.conda\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hsr_char_stats.json'"
     ]
    }
   ],
   "source": [
    "TRAILBLAZER_ORDER = [\n",
    "    'Caelus - Destruction',\n",
    "    'Stelle - Destruction',\n",
    "    'Caelus - Preservation',\n",
    "    'Stelle - Preservation'\n",
    "]\n",
    "dfs = df_list.copy()\n",
    "names = name_list.copy()\n",
    "\n",
    "def convert_to_json(df):\n",
    "    char_name = df['Name'][0]\n",
    "    df = df.T\n",
    "    df.columns = df.iloc[1, :]\n",
    "    df = df.iloc[2:, :]\n",
    "    df = df.fillna(method='ffill')\n",
    "    df['CRIT Rate'] = df['CRIT Rate'].replace('[%.]', '', regex=True).astype(float)/1000\n",
    "    df['CRIT DMG'] = df['CRIT DMG'].replace('[%.]', '', regex=True).astype(float)/1000\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    df_json = json.loads(df.to_json())\n",
    "    return_json = {char_name: df_json}\n",
    "    return return_json\n",
    "\n",
    "character_stats = []\n",
    "for df in dfs:\n",
    "    character_stats.append(convert_to_json(df))\n",
    "\n",
    "with open('../character_logic/data/hsr_char_stats.json', 'w') as f:\n",
    "    json.dump(character_stats, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame index must be unique for orient='columns'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols:\n\u001b[0;32m     11\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mapply(convert_values)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhsr_char_stats.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:2650\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[1;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[0;32m   2647\u001b[0m config\u001b[38;5;241m.\u001b[39mis_nonnegative_int(indent)\n\u001b[0;32m   2648\u001b[0m indent \u001b[38;5;241m=\u001b[39m indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 2650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\json\\_json.py:161\u001b[0m, in \u001b[0;36mto_json\u001b[1;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 161\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lines:\n\u001b[0;32m    174\u001b[0m     s \u001b[38;5;241m=\u001b[39m convert_to_line_delimits(s)\n",
      "File \u001b[1;32mc:\\Users\\andre\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\json\\_json.py:217\u001b[0m, in \u001b[0;36mWriter.__init__\u001b[1;34m(self, obj, orient, date_format, double_precision, ensure_ascii, date_unit, index, default_handler, indent)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent \u001b[38;5;241m=\u001b[39m indent\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andre\\.conda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\json\\_json.py:274\u001b[0m, in \u001b[0;36mFrameWriter._format_axes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mTry to format axes if they are datelike.\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame index must be unique for orient=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     )\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    281\u001b[0m ):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame columns must be unique for orient=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame index must be unique for orient='columns'."
     ]
    }
   ],
   "source": [
    "'''\n",
    "dfs = df_list.copy()\n",
    "names = name_list.copy()\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i]['LVL'] = dfs[i]['LVL'].fillna('Aggro')\n",
    "    dfs[i].insert(0, 'Name', [names[i], *[np.nan for i in range(len(dfs[i]) - 1)]])\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "numeric_cols = [col for col in df.columns if any(char.isdigit() for char in col)]\n",
    "\n",
    "def convert_values(value):\n",
    "    value_str = str(value)\n",
    "    if '%' in value_str:\n",
    "        return float(value_str.strip('%'))/100\n",
    "    else:\n",
    "        return float(value_str)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].apply(convert_values)\n",
    "\n",
    "df.to_json('hsr_char_stats.json')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
